{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Think of question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No code for this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Obtain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I just grabbed a training-wheels dataset from Kaggle for simplicity:\n",
    "[the Titanic Survival dataset](https://www.kaggle.com/c/titanic).)\n",
    "\n",
    "Maybe we can talk about obtaining data more in a later session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 & 4. Explore data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see some possible issues, even in the first 10 rows:\n",
    "* There are columns which are (most likely) unique to each passenger, and so useless or even\n",
    "  confusing to our classifier, like `PassengerId`, `Name`, and `Ticket`.\n",
    "* There are missing values in both the `Age` and `Cabin` columns, represented by the value `NaN`\n",
    "  (for \"Not a Number\", a term inherited from the IEEE floating-point number standard).\n",
    "* Some discrete-valued columns have already been transformed into numerical values (`Survived`, `Pclass`),\n",
    "  but others have not (`Sex`, `Embarked`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, step 1: drop columns unique to passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.drop(labels=['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html))\n",
    "removes rows or columns from a DataFrame (performing the removal in-place here,\n",
    "rather than returning a copy with the specified labels dropped). `axis=1` indicates that\n",
    "the labels we're providing are columns, rather than rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that we could extract some useful information for a classifier from\n",
    "the `Name` field, but we won't try today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2         1       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4         0       3    male  35.0      0      0   8.0500   NaN        S\n",
       "5         0       3    male   NaN      0      0   8.4583   NaN        Q\n",
       "6         0       1    male  54.0      0      0  51.8625   E46        S\n",
       "7         0       3    male   2.0      3      1  21.0750   NaN        S\n",
       "8         1       3  female  27.0      0      2  11.1333   NaN        S\n",
       "9         1       2  female  14.0      1      0  30.0708   NaN        C"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, step 2: handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see how widespread this problem is.\n",
    "\n",
    "([`DataFrame.isna()` documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isna.html),\n",
    "[`DataFrame.sum()` documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a lot! What proportion is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0.000000\n",
       "Pclass      0.000000\n",
       "Sex         0.000000\n",
       "Age         0.198653\n",
       "SibSp       0.000000\n",
       "Parch       0.000000\n",
       "Fare        0.000000\n",
       "Cabin       0.771044\n",
       "Embarked    0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.isna().sum() / len(titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 20% of passengers don't have an age listed. This could be an issue, but\n",
    "throwing away data - either those passengers, or age altogether - seems like\n",
    "a bad idea if we can avoid it.\n",
    "\n",
    "Nearly 80% of passengers lack cabin information, which is much more troublesome.\n",
    "We're probably better off just deleting that column entirely.\n",
    "\n",
    "As for the 2 passengers lacking information on where they embarked, that's probably\n",
    "easy to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning, step 3(a): replace missing age data with the median age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to be clever and match passengers without an age to similar passengers based\n",
    "on other columns, but let's just do the easy thing right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Age'].fillna(value=titanic_data['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([`DataFrame.fillna` documentation](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.fillna.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning, step 3(b): remove `Cabin` entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.drop(labels='Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning, step 3(c): replace the missing `Embarked` data with the most common value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Embarked'].fillna(value=titanic_data['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S\n",
       "5         0       3    male  28.0      0      0   8.4583        Q\n",
       "6         0       1    male  54.0      0      0  51.8625        S\n",
       "7         0       3    male   2.0      3      1  21.0750        S\n",
       "8         1       3  female  27.0      0      2  11.1333        S\n",
       "9         1       2  female  14.0      1      0  30.0708        C"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning, step 3: transform categorical variables into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the `LabelEncoder` class from the `sklearn.prepocessing` module, but the\n",
    "task we have before us is so simple that we'll just do it by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sex` is easy - we'll transform it into a boolean.\n",
    "\n",
    "(In general we might need more than two categories, but in this dataset a boolean\n",
    "suffices.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Sex'] = (titanic_data['Sex'] == 'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embarked` will require slightly more work - we generate a dictionary and map that way.\n",
    "\n",
    "(This is basically how the `LabelEncoder` I mentioned above works under the hood.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mapper = {label: idx for idx, label in enumerate(titanic_data['Embarked'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': 0, 'C': 1, 'Q': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Embarked'] = titanic_data['Embarked'].apply(embarked_mapper.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([`DataFrame.apply()` documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass    Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3  False  22.0      1      0   7.2500         0\n",
       "1         1       1   True  38.0      1      0  71.2833         1\n",
       "2         1       3   True  26.0      0      0   7.9250         0\n",
       "3         1       1   True  35.0      1      0  53.1000         0\n",
       "4         0       3  False  35.0      0      0   8.0500         0\n",
       "5         0       3  False  28.0      0      0   8.4583         2\n",
       "6         0       1  False  54.0      0      0  51.8625         0\n",
       "7         0       3  False   2.0      3      1  21.0750         0\n",
       "8         1       3   True  27.0      0      2  11.1333         0\n",
       "9         1       2   True  14.0      1      0  30.0708         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! Harder to read for a human, but much easier for a classifier.\n",
    "\n",
    "Keep in mind that the decisions we had to make regarding missing data, and what\n",
    "to remove, could have consequences for our model performance. In a real project,\n",
    "we'd probably compare a couple of different solutions to be sure we're making\n",
    "a good choice.\n",
    "\n",
    "In a more complex project, we'd probably be doing more data visualization before\n",
    "diving in, but this is a pretty simple dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select a method / model to answer question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a decision tree classifier, because they're simple and neat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(`sklearn` is the module name for `scikit-learn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation for this model](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Select a metric to score performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the simplest possible metric - the raw accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$accuracy(actual, predicted) = \\frac{\\text{# labels correct}}{\\text{total # labels}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation for this function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Split data according to cross-validation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're again choosing the simplest option - the holdout method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation for this function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to split off the variable we're hoping to predict first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_survived = titanic_data['Survived']\n",
    "full_predictors = titanic_data.drop(labels='Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.2 # 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_predictors,\n",
    " test_predictors,\n",
    " train_survived,\n",
    " test_survived) = train_test_split(full_predictors,\n",
    "                                   full_survived,\n",
    "                                   test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_model_default = DecisionTreeClassifier() # using default (hyper)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_model_default.fit(train_predictors, train_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Score model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survived_predicted = dtree_model_default.predict(test_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when using our decision tree: 0.760\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when using our decision tree: {:.3f}'.format(accuracy_score(test_survived, test_survived_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, a bit less than 80%. Is that good? How do we tell?\n",
    "\n",
    "Well, the output variable is boolean (survived or not), so at least we've\n",
    "done better than someone just flipping a coin.\n",
    "\n",
    "But if the two classes aren't evenly spread in our dataset, we could get\n",
    "better-than-chance performance simply by predicting that the likelier outcome\n",
    "befell everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when predicting no survival: 0.631\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when predicting no survival: {:.3f}'.format(1 - test_survived.sum() / len(test_survived)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm! Just by claiming that everyone died, we could top 60% correct.\n",
    "\n",
    "(Note that our dataset isn't quite representative of the historical data - \n",
    "roughly 68% of the people on board died.)\n",
    "\n",
    "But at about 80%, we're still doing better than this dumb predictor.\n",
    "\n",
    "There's one more dirt-simple predictor. The sinking of the\n",
    "Titanic is partially responsible for the prevalence of the \"women and children\n",
    "first\" idea in popular culture - 75% of the women on board survived,\n",
    "while only 20% of the men did. So let's see what happens if we predict that\n",
    "only women survive.\n",
    "\n",
    "(Note that this precise gender imbalance in survival doesn't appear in most other\n",
    "historical shipwrecks - men are usually more likely to survive, in fact. See\n",
    "[this paper in PNAS](http://www.pnas.org/content/early/2012/07/23/1207156109.short).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when predicting only women survive: 0.816\n"
     ]
    }
   ],
   "source": [
    "# remember that we mapped 'female' to True and 'male' to False\n",
    "print('accuracy when predicting only women survive: {:.3f}'.format(accuracy_score(test_survived, test_predictors['Sex'] == True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dang! Just by predicting that only women survive, we can match or beat\n",
    "our decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Revisit prior steps as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10(a): our cross-validation is poor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We described four models above:\n",
    "\n",
    "1. Chance: flip a coin for each passenger to see whether they survived.\n",
    "2. Most prevalent: predict the most likely outcome in the dataset (\"did not survive\") for every passenger.\n",
    "3. Hand-selected decision (based on prior knowledge or intuition): predict that only women survived.\n",
    "4. Our machine learning model: decision tree trained on 80% of the data.\n",
    "\n",
    "We then compared their performance on the 20% of the original data we held aside for testing.\n",
    "\n",
    "If we use this process to decide which prediction model to use, we run into a problem.\n",
    "Our \"total model\" now has an additional level of abstraction: it can be described as \"whichever model\n",
    "from the list above that did best on our testing dataset.\" But this \"total model\" has folded\n",
    "information from our test data into itself - that's how we decided which of the four to use.\n",
    "\n",
    "We can no longer be certain our \"total model\" will perform this well on a further test dataset.\n",
    "\n",
    "Just as we can describe our problem as one of nested models, our solution lies in nesting\n",
    "our train-test split, with the portion of the old training set laid aside for model\n",
    "comparison now called the \"validation\" set:\n",
    "\n",
    "![train-test-validate](train_test_validate_50pct.png)\n",
    "\n",
    "([image source](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7))\n",
    "\n",
    "So we train our model (model 4 above, as models 1-3 don't need training) on the set\n",
    "labeled \"train.\" We then compare models using the \"validation\" set, and our final reported\n",
    "prediction score would be generated using the \"test\" set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(a), re-doing step 7: cross-validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to do this is just to call `train_test_split()` again on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_predictors_2ndpass,\n",
    " validation_predictors,\n",
    " train_survived_2ndpass,\n",
    " validation_survived) = train_test_split(train_predictors,\n",
    "                                         train_survived,\n",
    "                                         test_size=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(a), re-doing step 8: train the model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_model_cv_default = DecisionTreeClassifier() # using default (hyper)parameters again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_model_cv_default.fit(train_predictors_2ndpass, train_survived_2ndpass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(a), re-doing step 9: evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_survived_predicted = dtree_model_cv_default.predict(validation_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when using our decision tree (validation set): 0.783\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when using our decision tree (validation set): {:.3f}'.format(accuracy_score(validation_survived, validation_survived_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when predicting no survival (validation set): 0.615\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when predicting no survival (validation set): {:.3f}'.format(1 - validation_survived.sum() / len(validation_survived)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when predicting only women survive (validation set): 0.853\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when predicting only women survive (validation set): {:.3f}'.format(accuracy_score(validation_survived, validation_predictors['Sex'] == True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each of our \"models\" is still performing in the same ballpark.\n",
    "\n",
    "If we pick our decision tree, how does it do on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_survived_predicted_cv = dtree_model_cv_default.predict(test_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when using our decision tree (test set): 0.715\n"
     ]
    }
   ],
   "source": [
    "print('accuracy when using our decision tree (test set): {:.3f}'.format(accuracy_score(test_survived, test_survived_predicted_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we haven't really affected our numbers (even though we're training the\n",
    "decision tree on 20% less data).\n",
    "\n",
    "But we **can** be more confident now that our chosen model will perform as\n",
    "advertised on data it's never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(a) final note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still not doing cross-validation fully correctly, because the holdout\n",
    "method that we're using to generate the train/test/validation sets could be selecting\n",
    "biased samples, and thus we might be overfitting to those.\n",
    "\n",
    "The really **right** way to do this would be to use actual folded cross-validation, where\n",
    "you average performance on all folds is what you use to determine which model to run on\n",
    "the test set. (Check out [the documentation for `sklearn`'s cross validation procedures](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "and try it for yourself.)\n",
    "\n",
    "(Of course, as with seemingly so many things in this field, there are those who disagree -\n",
    "some people prefer rigorous bootstrapping to split-sample cross-validation, and they might\n",
    "be right. We definitely don't have time to go into this today.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10(b): we want to tweak the model's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees have a tendency to overfit, and this may be part of why we're not\n",
    "performing better on the validation and test sets.\n",
    "\n",
    "There are a number of parameters used to determine how a decision tree is fit.\n",
    "\n",
    "We'll try fiddling with the `min_samples_split` parameter.\n",
    "\n",
    "At each branch point of a decision tree, there is a certain pool of samples remaining,\n",
    "and the fitting algorithm tries to use a feature in the predictors to segregate them\n",
    "according to the outcome variable. One of the ways that decision trees can overfit is\n",
    "by continuing to split until each decision produces pools with only a small number of\n",
    "samples in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(b), re-doing step 8: train the model on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value for `min_samples_split` is 2, which is pretty small. Let's try a\n",
    "few larger values, and compare their performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mss_values = [2, 5, 10, 20, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_models_cv_mss_tuning = {mss: DecisionTreeClassifier(min_samples_split=mss) for mss in mss_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtc in dtree_models_cv_mss_tuning.values():\n",
    "    dtc.fit(train_predictors_2ndpass, train_survived_2ndpass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(b), re-doing step 9: evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using decision tree with mss of 2 (validation set): 0.776\n",
      "accuracy using decision tree with mss of 5 (validation set): 0.804\n",
      "accuracy using decision tree with mss of 10 (validation set): 0.804\n",
      "accuracy using decision tree with mss of 20 (validation set): 0.811\n",
      "accuracy using decision tree with mss of 50 (validation set): 0.825\n",
      "accuracy using decision tree with mss of 75 (validation set): 0.853\n",
      "accuracy using decision tree with mss of 100 (validation set): 0.776\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "for mss, dtc in dtree_models_cv_mss_tuning.items():\n",
    "    outcomes.append(accuracy_score(validation_survived, dtc.predict(validation_predictors)))\n",
    "    print('accuracy using decision tree with mss of {} (validation set): {:.3f}'.format(mss, outcomes[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting these results, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dtree_models_cv_mss_tuning.keys(), outcomes)\n",
    "plt.ylim(0.7, 0.9)\n",
    "plt.xlabel('min_samples_split value')\n",
    "plt.ylabel('accuracy score')\n",
    "plt.title('decision tree accuracy on validation set');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And running the best model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy when using our best decision tree (mss=75) (test set): 0.832\n"
     ]
    }
   ],
   "source": [
    "best_outcome = max(outcomes)\n",
    "best_mss = mss_values[outcomes.index(best_outcome)]\n",
    "best_dtc = dtree_models_cv_mss_tuning[best_mss]\n",
    "print('accuracy when using our best decision tree (mss={}) (test set): {:.3f}'.format(best_mss,\n",
    "                                                                                        accuracy_score(test_survived,\n",
    "                                                                                        best_dtc.predict(test_predictors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement (hopefully). Not superb - further work could probably bring us higher,\n",
    "but this is OK for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10(c): we'd like to use a different metric to score the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is simple and easy to interpret, but isn't appropriate or\n",
    "useful in many cases. In our case, if the cost (determined by us, our environment,\n",
    "or our business case) of getting the classification wrong is different\n",
    "depending on the direction of the error, accuracy won't be as helpful.\n",
    "\n",
    "We'll try to apply another metric, the [F1 score](https://en.wikipedia.org/wiki/F1_score).\n",
    "Let's first take a look at the confusion matrix.\n",
    "\n",
    "| *            | Survived         | Died           | (predicted) |\n",
    "| ------------ | ---------------- | -------------- | ----------- |\n",
    "| **Survived** | true positive    | false negative |             |\n",
    "| **Died**     | false positive   | true negative  |             |\n",
    "| **(actual)** |                                                 |\n",
    "\n",
    "The **precision** of a model is the true positives out of the total predicted positives:\n",
    "\n",
    "$$ precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "The **recall** of a model is the true positives out of the total actual positives:\n",
    "\n",
    "$$ recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "And the F1 score is a combination of these values (specifically, the harmonic mean):\n",
    "\n",
    "$$ F_1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} $$\n",
    "\n",
    "Briefly, the F1 score can sometimes detect poor model performance where accuracy might not,\n",
    "particularly when one label dominates the other in the dataset (i.e., we're trying to\n",
    "identify interesting things, and most things aren't interesting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10(c), re-doing step 9: evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score when predicting no survival (validation set): {:.3f}'.format(f1_score(validation_survived,\n",
    "                                                                                      [False] * len(validation_survived))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(So if there are no predicted survivals, we can't use the F1 score because its denominator is 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score when predicting only women survive (validation set): {:.3f}'.format(f1_score(validation_survived, validation_predictors['Sex'] == True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_f1 = []\n",
    "for mss, dtc in dtree_models_cv_mss_tuning.items():\n",
    "    outcomes_f1.append(f1_score(validation_survived, dtc.predict(validation_predictors)))\n",
    "    print('F1 score using decision tree with mss of {} (validation set): {:.3f}'.format(mss, outcomes_f1[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outcome_f1 = max(outcomes_f1)\n",
    "best_mss_f1 = mss_values[outcomes_f1.index(best_outcome_f1)]\n",
    "best_dtc_f1 = dtree_models_cv_mss_tuning[best_mss_f1]\n",
    "print('F1 score when using our best decision tree (mss={}) (test set): {:.3f}'.format(best_mss_f1,\n",
    "                                                                                      f1_score(test_survived,\n",
    "                                                                                      best_dtc_f1.predict(test_predictors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. When evaluating performance using the F1 score, we do worse than the only-women-survive heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
